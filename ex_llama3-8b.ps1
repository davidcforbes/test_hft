python test_pipeline.py --task text-generation --model meta-llama/Meta-Llama-3-8B-Instruct --prompt "Explain photosynthesis to a curious 8-year-old" --8b --max-new-tokens 8098
